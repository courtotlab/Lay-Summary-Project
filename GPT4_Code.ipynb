{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fc43f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: openpyxl in ./.venv/lib/python3.13/site-packages (3.1.5)\n",
      "Requirement already satisfied: metapub in ./.venv/lib/python3.13/site-packages (0.6.4)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.13/site-packages (0.24.0)\n",
      "Requirement already satisfied: tensorflow in ./.venv/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: ragas==0.3.7 in ./.venv/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.13/site-packages (1.0.2)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (1.109.1)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.13/site-packages (0.12.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (1.2.1)\n",
      "Requirement already satisfied: tf-keras in ./.venv/lib/python3.13/site-packages (2.20.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: biopython in ./.venv/lib/python3.13/site-packages (1.86)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.13/site-packages (4.14.2)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.13/site-packages (6.0.2)\n",
      "Requirement already satisfied: textstat in ./.venv/lib/python3.13/site-packages (0.7.10)\n",
      "Requirement already satisfied: nest_asyncio in ./.venv/lib/python3.13/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (2.3.4)\n",
      "Requirement already satisfied: datasets>=4.0.0 in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (4.3.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (2.12.3)\n",
      "Requirement already satisfied: appdirs in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (5.6.3)\n",
      "Requirement already satisfied: typer in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (0.20.0)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (14.2.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (4.67.1)\n",
      "Requirement already satisfied: instructor in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (1.12.0)\n",
      "Requirement already satisfied: gitpython in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (3.1.45)\n",
      "Requirement already satisfied: pillow>=10.4.0 in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (12.0.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (3.5)\n",
      "Requirement already satisfied: scikit-network in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (0.33.3)\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (1.0.1)\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.13/site-packages (from ragas==0.3.7) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.13/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from metapub) (80.9.0)\n",
      "Requirement already satisfied: lxml_html_clean in ./.venv/lib/python3.13/site-packages (from metapub) (0.4.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from metapub) (2.32.5)\n",
      "Requirement already satisfied: eutils in ./.venv/lib/python3.13/site-packages (from metapub) (0.6.0)\n",
      "Requirement already satisfied: habanero in ./.venv/lib/python3.13/site-packages (from metapub) (2.3.0)\n",
      "Requirement already satisfied: tabulate in ./.venv/lib/python3.13/site-packages (from metapub) (0.9.0)\n",
      "Requirement already satisfied: cssselect in ./.venv/lib/python3.13/site-packages (from metapub) (1.3.0)\n",
      "Requirement already satisfied: unidecode in ./.venv/lib/python3.13/site-packages (from metapub) (1.4.0)\n",
      "Requirement already satisfied: docopt in ./.venv/lib/python3.13/site-packages (from metapub) (0.6.2)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.13/site-packages (from metapub) (1.17.0)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.13/site-packages (from metapub) (15.0.1)\n",
      "Requirement already satisfied: python-Levenshtein in ./.venv/lib/python3.13/site-packages (from metapub) (0.27.1)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from metapub) (6.0.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./.venv/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.13/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->metapub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->metapub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->metapub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->metapub) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core->ragas==0.3.7) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core->ragas==0.3.7) (0.4.38)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-core->ragas==0.3.7) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->ragas==0.3.7) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas==0.3.7) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas==0.3.7) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas==0.3.7) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.0.0->ragas==0.3.7) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.0.0->ragas==0.3.7) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.0.0->ragas==0.3.7) (0.4.2)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langchain) (1.0.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.13/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.13/site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: pyphen in ./.venv/lib/python3.13/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.13/site-packages (from textstat) (3.9.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.venv/lib/python3.13/site-packages (from datasets>=4.0.0->ragas==0.3.7) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from datasets>=4.0.0->ragas==0.3.7) (0.4.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.13/site-packages (from datasets>=4.0.0->ragas==0.3.7) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=4.0.0->ragas==0.3.7) (1.22.0)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.13/site-packages (from coloredlogs->metapub) (10.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.13/site-packages (from gitpython->ragas==0.3.7) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython->ragas==0.3.7) (5.0.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in ./.venv/lib/python3.13/site-packages (from instructor->ragas==0.3.7) (0.17.0)\n",
      "Requirement already satisfied: pre-commit>=4.3.0 in ./.venv/lib/python3.13/site-packages (from instructor->ragas==0.3.7) (4.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich->ragas==0.3.7) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich->ragas==0.3.7) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer->ragas==0.3.7) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.13/site-packages (from typer->ragas==0.3.7) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->ragas==0.3.7) (0.1.2)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in ./.venv/lib/python3.13/site-packages (from pre-commit>=4.3.0->instructor->ragas==0.3.7) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in ./.venv/lib/python3.13/site-packages (from pre-commit>=4.3.0->instructor->ragas==0.3.7) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in ./.venv/lib/python3.13/site-packages (from pre-commit>=4.3.0->instructor->ragas==0.3.7) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in ./.venv/lib/python3.13/site-packages (from pre-commit>=4.3.0->instructor->ragas==0.3.7) (20.35.4)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in ./.venv/lib/python3.13/site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas==0.3.7) (0.4.0)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in ./.venv/lib/python3.13/site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas==0.3.7) (4.5.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langchain-community->ragas==0.3.7) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./.venv/lib/python3.13/site-packages (from langchain-community->ragas==0.3.7) (2.0.44)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./.venv/lib/python3.13/site-packages (from langchain-community->ragas==0.3.7) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.venv/lib/python3.13/site-packages (from langchain-community->ragas==0.3.7) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from langchain-community->ragas==0.3.7) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas==0.3.7) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas==0.3.7) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community->ragas==0.3.7) (1.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas==0.3.7) (1.1.0)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in ./.venv/lib/python3.13/site-packages (from python-Levenshtein->metapub) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in ./.venv/lib/python3.13/site-packages (from Levenshtein==0.27.1->python-Levenshtein->metapub) (3.14.1)\n"
     ]
    }
   ],
   "source": [
    "# Install and import necessary libraries\n",
    "\n",
    "!python3 -m pip install pandas openpyxl metapub transformers torch torchvision tensorflow ragas==0.3.7 langchain-openai langchain openai tiktoken python-dotenv tf-keras scikit-learn biopython beautifulsoup4 lxml textstat openai nest_asyncio\n",
    "import pandas as pd\n",
    "import json\n",
    "from metapub import PubMedFetcher\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import reduce\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from Bio import Entrez\n",
    "from bs4 import BeautifulSoup\n",
    "from ragas.metrics import faithfulness\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from datasets import Dataset\n",
    "import csv\n",
    "\n",
    "import time\n",
    "import textstat\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "import tqdm\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb1098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Loaded: 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...\n",
      "Entrez email set: t2yu@oicr.on.ca\n",
      "Entrez API key: da059acf5271585c53851508e6054b7f0807\n",
      "Lay Summarizer Configuration: \n",
      " Number of articles: 1 \n",
      " Maximum word length: 350 \n",
      " Minimum word length: 250\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from your .env file, or export your api key\n",
    "# load_dotenv(\"\")\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"API key not found.\")\n",
    "else:\n",
    "    print(f\"API Key Loaded: {openai_api_key}...\")\n",
    "\n",
    "# OpenAI client\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Set location of configuration file, to load configuration variables\n",
    "with open(\"./config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "num_of_articles = config[\"num_of_articles\"]\n",
    "max_summary_length = config[\"max_summary_length\"]\n",
    "min_summary_length = config[\"min_summary_length\"]\n",
    "\n",
    "# Set an Entrez email within the config file\n",
    "Entrez.email = config[\"entrez_email\"]\n",
    "Entrez.api_key = config[\"entrez_api_key\"]\n",
    "print(f\"Entrez email set: {Entrez.email}\")\n",
    "print(f\"Entrez API key: {Entrez.api_key}\")\n",
    "print(f\"Lay Summarizer Configuration: \\n Number of articles: {num_of_articles} \\n Maximum word length: {max_summary_length} \\n Minimum word length: {min_summary_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c61905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch full texts \n",
    "def fetch_full_texts(pmids, fetcher):\n",
    "    time.sleep(1) \n",
    "    full_texts, titles = {}, {}\n",
    "\n",
    "    print(f\"Retrieved PMIDs: {pmids}\")\n",
    "    print(f\"Number of PMIDs retrieved: {len(pmids)}\")\n",
    "\n",
    "    for pmid in pmids:\n",
    "        try:\n",
    "            article = fetcher.article_by_pmid(pmid)\n",
    "            titles[pmid] = article.title\n",
    "            \n",
    "            pmcid = article.pmc\n",
    "            if pmcid:\n",
    "                handle = Entrez.efetch(db=\"pmc\", id=pmcid, rettype=\"xml\", retmode=\"xml\")\n",
    "                xml_data = handle.read()\n",
    "                handle.close()\n",
    "\n",
    "                soup = BeautifulSoup(xml_data, features=\"xml\")\n",
    "\n",
    "                paragraphs = soup.find_all(\"p\")\n",
    "                sections = soup.find_all(\"sec\")\n",
    "\n",
    "                text_chunks = [p.get_text() for p in paragraphs]\n",
    "                if not text_chunks and sections:\n",
    "                    # Fallback to extracting from section text\n",
    "                    text_chunks = [s.get_text() for s in sections]\n",
    "\n",
    "                full_text = \"\\n\".join(p.get_text() for p in paragraphs)\n",
    "                full_texts[pmid] = full_text if full_text.strip() else \"Full text unavailable\"\n",
    "                \n",
    "            else:\n",
    "                full_texts[pmid] = \"Full text unavailable\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching full text for PMID {pmid}: {e}\")\n",
    "            titles[pmid] = titles.get(pmid, \"Unavailable\")\n",
    "            full_texts[pmid] = \"Full text unavailable\"\n",
    "    return titles, full_texts\n",
    "    \n",
    "\n",
    "def fetch_abstracts(pmids, fetcher):\n",
    "    abstracts = {}\n",
    "    titles = {}\n",
    "    \n",
    "    for pmid in pmids:\n",
    "        try:\n",
    "            article = fetcher.article_by_pmid(pmid)\n",
    "            titles[pmid] = article.title\n",
    "            abstracts[pmid] = article.abstract if article.abstract else \"Abstract unavailable\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching abstract for PMID {pmid}: {e}\")\n",
    "            titles[pmid] = titles.get(pmid, \"Unavailable\")\n",
    "            abstracts[pmid] = \"Abstract unavailable\"\n",
    "    return titles, abstracts\n",
    "\n",
    "async_client = AsyncOpenAI(api_key=openai_api_key)\n",
    "\n",
    "async def async_summarize(pmid, text, max_length):\n",
    "    if not text or text == \"Full text unavailable\":\n",
    "        return pmid, \"No text available\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"Summarize this article in 250 to {max_length} words for a 2nd grade lay audience using simple words. \"\n",
    "        f\"The tone should be casual. Avoid emotive or negative language such as battle or fight. \"\n",
    "        f\"Keep words under 4 syllables and sentences under 10 words: {text}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = await async_client.chat.completions.create(\n",
    "            model=\"gpt-5-mini\", #\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes medical research.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=1,\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        return pmid, content\n",
    "    except Exception as e:\n",
    "        return pmid, f\"Error summarizing: {e}\"\n",
    "\n",
    "async def gpt4_summarize_async(texts, max_length, concurrency=15):\n",
    "    semaphore = asyncio.Semaphore(concurrency)\n",
    "\n",
    "    async def limited_summary(pmid, text):\n",
    "        async with semaphore:\n",
    "            return await async_summarize(pmid, text, max_length)\n",
    "\n",
    "    tasks = [limited_summary(pmid, text) for pmid, text in texts.items()]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return dict(results)\n",
    "\n",
    "\n",
    "def compute_readability(summary):\n",
    "    if summary and summary != \"No text available\":\n",
    "        flesch_score = textstat.flesch_reading_ease(summary)\n",
    "        grade_level = textstat.flesch_kincaid_grade(summary)\n",
    "        return flesch_score, grade_level\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def compute_ragas_faithfulness(summaries, references, prompt):\n",
    "    evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "    print(evaluator_llm)\n",
    "    data = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": []\n",
    "    }\n",
    "    valid_pmids = []\n",
    "\n",
    "    for pmid, summary in summaries.items():\n",
    "        reference = references.get(pmid)\n",
    "        if (\n",
    "            summary \n",
    "            and reference \n",
    "            and summary != \"No text available\" \n",
    "            and reference != \"Full text unavailable\"\n",
    "        ):\n",
    "            data[\"question\"].append(prompt)\n",
    "            data[\"answer\"].append(summary)\n",
    "            data[\"contexts\"].append([reference])\n",
    "            valid_pmids.append(pmid)\n",
    "            print(\"RAGAS data:\", data)\n",
    "\n",
    "    \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    results = evaluate(dataset, metrics=[faithfulness], llm=evaluator_llm)\n",
    "    print(\"RAGAS results:\", results)\n",
    "    return dict(zip(valid_pmids, results[\"faithfulness\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f109742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39119834']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use if you need to query for PMIDS\n",
    "if \"queries\" in config:\n",
    "\n",
    "    for query in config[\"queries\"]:\n",
    "            keyword = query[\"keyword\"]\n",
    "            output_file = query[\"output_file\"]\n",
    "\n",
    "            fetch = PubMedFetcher()\n",
    "            pmids = fetch.pmids_for_query(f\"{keyword} AND pubmed pmc open access[filter]\", retmax=num_of_articles)\n",
    "\n",
    "\n",
    "            print(pmids)\n",
    "\n",
    "            #writes the queried PMIDs to a txt file\n",
    "            with open(\"pmids_queried.txt\", \"w\") as f:\n",
    "                for pmid in pmids:\n",
    "                    f.write(pmid + \"\\n\")\n",
    "\n",
    "            \n",
    "else:\n",
    "    print(\"No queries found in the configuration file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7ad773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if you have a file of PMIDs to summarize and calculate metrics\n",
    "if \"pmid_file\" in config:\n",
    "    pmid_file = config[\"pmid_file\"]\n",
    "    with open(pmid_file, \"r\") as f:\n",
    "        pmids = [line.strip() for line in f.readlines()]\n",
    "    print(f\"Loaded {len(pmids)} PMIDs from {pmid_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2677839a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID 39119834: Methuosis Inducer SGI-1027 Cooperates with Everolimus to Promote Apoptosis and Pyroptosis by Triggering Lysosomal Membrane Permeability in Renal Cancer.\n",
      "Authors: Luo Y, Guan B, Deng X, Bai P, Huang H, Miao C, Sun A, Li Z, Yang D, Wang X, Shao Z, Wu Y, Xing J, Chen B, Wang T\n",
      "Journal: Adv Sci (Weinh)\n",
      "---\n",
      "Retrieved PMIDs: ['39119834']\n",
      "Number of PMIDs retrieved: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 00:14:22 ML8136-T2YU.local httpx[7485] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:14:40 ML8136-T2YU.local httpx[7485] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "llm_factory() got an unexpected keyword argument 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     57\u001b[39m ragas_prompt = (\u001b[33m\"\u001b[39m\u001b[33mSummarize this article in 250 to 350 words for a 2nd grade lay audience using simple words.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     58\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThe tone should be casual.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mAvoid emotive or negative language such as battle or fight.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mKeep words under 4 syllables and sentences under 10 words.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m                 )\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Compute RAGAS faithfulness\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m abstract_ragas_faithfulness = \u001b[43mcompute_ragas_faithfulness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract_summaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstracts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mragas_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m fulltext_ragas_faithfulness = compute_ragas_faithfulness(full_text_summaries, full_texts, ragas_prompt)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Prepare DataFrames\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mcompute_ragas_faithfulness\u001b[39m\u001b[34m(summaries, references, prompt)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_ragas_faithfulness\u001b[39m(summaries, references, prompt):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     evaluator_llm = \u001b[43mllm_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-5-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43masync_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m    106\u001b[39m     \u001b[38;5;28mprint\u001b[39m(evaluator_llm)\n\u001b[32m    107\u001b[39m     data = {\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m    110\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontexts\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m    111\u001b[39m     }\n",
      "\u001b[31mTypeError\u001b[39m: llm_factory() got an unexpected keyword argument 'client'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prints article information for pmids retrieved\n",
    "for pmid in pmids:\n",
    "    article = fetch.article_by_pmid(pmid)\n",
    "    print(f\"PMID {pmid}: {article.title}\")\n",
    "    print(f\"Authors: {', '.join([str(a) for a in article.authors])}\")\n",
    "    print(f\"Journal: {article.journal}\")\n",
    "    print(\"---\")\n",
    "\n",
    "#Generates fulltext-based summaries\n",
    "titles, full_texts = fetch_full_texts(pmids, fetch)\n",
    "filtered_texts = {pmid: text for pmid, text in full_texts.items() if text != \"Full text unavailable\"}\n",
    "full_text_summaries = await gpt4_summarize_async(filtered_texts, max_length=max_summary_length)\n",
    "\n",
    "#Generates abstract-based summaries\n",
    "titles, abstracts = fetch_abstracts(pmids, fetch)\n",
    "abstract_summaries = await gpt4_summarize_async(abstracts, max_length=max_summary_length)\n",
    "\n",
    "links = {pmid: f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\" for pmid in pmids}\n",
    "\n",
    "\n",
    "# Calculates similarity between abstract vs full text summaries\n",
    "# Define the evaluate_similarity function\n",
    "def evaluate_similarity(abstract_summaries, full_text_summaries):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([abstract_summaries, full_text_summaries])\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return similarity[0][0]\n",
    "\n",
    "similarity_scores = {\n",
    "    pmid: evaluate_similarity(abstract_summaries[pmid], full_text_summaries[pmid])\n",
    "    for pmid in abstract_summaries\n",
    "    if abstract_summaries[pmid] != \"No text available\"\n",
    "    and full_text_summaries.get(pmid)\n",
    "    and full_text_summaries[pmid] != \"No text available\"\n",
    "}\n",
    "\n",
    "# Calculate readability scores for abstract summaries\n",
    "abstract_readability = {\n",
    "    pmid: compute_readability(abstract_summaries[pmid])\n",
    "    for pmid in abstract_summaries\n",
    "}\n",
    "\n",
    "# Calculate readability scores for full text summaries\n",
    "full_text_readability = {\n",
    "    pmid: compute_readability(full_text_summaries[pmid])\n",
    "    for pmid in full_text_summaries\n",
    "}\n",
    "\n",
    "\n",
    "# Full text availability\n",
    "full_text_availability = {\n",
    "    pmid: \"Available\" if full_texts[pmid] != \"Full text unavailable\" else \"Unavailable\"\n",
    "    for pmid in pmids\n",
    "}\n",
    "\n",
    "# Define the prompt used for summarization\n",
    "ragas_prompt = (\"Summarize this article in 250 to 350 words for a 2nd grade lay audience using simple words.\"\n",
    "                \"The tone should be casual.\"\n",
    "                \"Avoid emotive or negative language such as battle or fight.\"\n",
    "                \"Keep words under 4 syllables and sentences under 10 words.\"\n",
    "                )\n",
    "\n",
    "# Compute RAGAS faithfulness\n",
    "abstract_ragas_faithfulness = compute_ragas_faithfulness(abstract_summaries, abstracts, ragas_prompt)\n",
    "fulltext_ragas_faithfulness = compute_ragas_faithfulness(full_text_summaries, full_texts, ragas_prompt)\n",
    "\n",
    "\n",
    "# Prepare DataFrames\n",
    "Title = pd.DataFrame(list(titles.items()), columns=[\"pmid\", \"Title\"])\n",
    "Link = pd.DataFrame(list(links.items()), columns=[\"pmid\", \"Link\"])\n",
    "Abstract = pd.DataFrame(list(abstracts.items()), columns=[\"pmid\", \"Abstract\"])\n",
    "Abstract = Abstract.assign(\n",
    "    Abstract=lambda df: df[\"Abstract\"].str.replace(\"\\n\", \" \")\n",
    ")\n",
    "FullTextFlag = pd.DataFrame(list(full_text_availability.items()), columns=[\"pmid\", \"FullText_Availability\"])\n",
    "Abstract_Summary = pd.DataFrame(list(abstract_summaries.items()), columns=[\"pmid\", \"Abstract_Summary\"])\n",
    "Full_Text_Summary = pd.DataFrame(list(full_text_summaries.items()), columns=[\"pmid\", \"Full_Text_Summary\"])\n",
    "Similarity = pd.DataFrame(list(similarity_scores.items()), columns=[\"pmid\", \"Abstract_vs_FullText_Similarity\"])\n",
    "\n",
    "Abstract_Readability = pd.DataFrame([\n",
    "    {\"pmid\": pmid, \n",
    "    \"Abstract_Flesch_Reading_Ease\": scores[0], \n",
    "    \"Abstract_Flesch_Kincaid_Grade\": scores[1]}\n",
    "    for pmid, scores in abstract_readability.items()\n",
    "])\n",
    "\n",
    "\n",
    "Full_Text_Readability = pd.DataFrame([\n",
    "    {\"pmid\": pmid, \n",
    "    \"FullText_Flesch_Reading_Ease\": scores[0], \n",
    "    \"FullText_Flesch_Kincaid_Grade\": scores[1]}\n",
    "    for pmid, scores in full_text_readability.items()\n",
    "])\n",
    "\n",
    "# RAGAS faithfulness scores\n",
    "Abstract_RAGAS_Faithfulness = pd.DataFrame(list(abstract_ragas_faithfulness.items()), columns=[\"pmid\", \"Abstract_RAGAS_Faithfulness\"])\n",
    "FullText_RAGAS_Faithfulness = pd.DataFrame(list(fulltext_ragas_faithfulness.items()), columns=[\"pmid\", \"FullText_RAGAS_Faithfulness\"])\n",
    "\n",
    "\n",
    "# Combine all DataFrames\n",
    "data_frames = [\n",
    "    Title, \n",
    "    Link, \n",
    "    Abstract, \n",
    "    FullTextFlag, \n",
    "    Abstract_Summary, \n",
    "    Full_Text_Summary, \n",
    "    Similarity,\n",
    "    Abstract_Readability,\n",
    "    Full_Text_Readability,\n",
    "    Abstract_RAGAS_Faithfulness,\n",
    "    FullText_RAGAS_Faithfulness\n",
    "]\n",
    "\n",
    "# Combine all DataFrames\n",
    "df_full = reduce(lambda left, right: pd.merge(left, right, on=\"pmid\", how=\"outer\"), data_frames)\n",
    "\n",
    "# Print Availability Counts\n",
    "print(f\"Full Text Availability for keyword '{keyword}':\")\n",
    "availability_counts = df_full[\"FullText_Availability\"].value_counts()\n",
    "print(\"Full Text Availability Counts:\")\n",
    "print(availability_counts)\n",
    "\n",
    "# Filter to keep only articles with full text available\n",
    "df_full = df_full[df_full[\"FullText_Availability\"] == \"Available\"]\n",
    "\n",
    "# Save the DataFrame to a CSV file with a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_name, _ = os.path.splitext(output_file)\n",
    "output_file_with_timestamp = f\"{base_name}_{timestamp}.csv\"\n",
    "\n",
    "# Specify the output directory\n",
    "output_dir = Path(\"./output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "full_output_path = output_dir / output_file_with_timestamp\n",
    "df_full.to_csv(full_output_path, index=False)\n",
    "\n",
    "print(f\"Data for keyword '{keyword}' saved to: {output_file_with_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5734cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/6g39d69s7m35v6gzfsln6thr0000gp/T/ipykernel_7485/1854503017.py:105: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use the modern LLM providers instead: from ragas.llms.base import llm_factory; llm = llm_factory('gpt-4o-mini') or from ragas.llms.base import instructor_llm_factory; llm = instructor_llm_factory('openai', client=openai_client)\n",
      "  evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangchainLLMWrapper(langchain_llm=ChatOpenAI(...))\n",
      "RAGAS data: {'question': ['Summarize this article in 250 to 350 words for a 2nd grade lay audience using simple words.The tone should be casual.Avoid emotive or negative language such as battle or fight.Keep words under 4 syllables and sentences under 10 words.'], 'answer': ['This work looks at drugs for kidney cancer.  \\nOne drug, everolimus, helps at first.  \\nBut it can stop working over time.  \\nThe team looked for new ways to help.  \\nThey tested a second drug, SGI-1027.  \\nSGI-1027 can change how DNA acts.  \\nIt makes cells fill with big bubbles.  \\nThe bubbles can make the cell break.  \\nThe team found SGI-1027 helps everolimus.  \\nThe two drugs work well when used together.  \\nThey slow tumor cell growth and move.  \\nThey cut how cells spread and invade.  \\nThe mix makes cells die in two ways.  \\nOne way is a calm, planned shut down.  \\nThe other way makes cells swell and pop.  \\nA protein called GSDME joins the pop way.  \\nKidney cancer cells had more GSDME inside.  \\nTheir lysosome bags were also more busy.  \\nLysosomes are the cell clean up bags.  \\nThese bags can get leaky from the drugs.  \\nThe leaks can push cells to die fast.  \\nThis gives a clear chance to treat cells.  \\nThe drug mix worked well in small mice tests.  \\nTumors were small and the mice did fine.  \\nNo big harm showed with the mix dose.  \\nThis study shows SGI-1027 can kill tumor cells.  \\nIt also shows SGI-1027 can help everolimus work.  \\nThe find may help when everolimus stops working.  \\nMore tests are needed to see it in people.  \\nBut this work gives new hope for kidney care.'], 'contexts': [['The mTOR inhibitor everolimus has been approved as a sequential or second-line therapy for renal cell carcinoma (RCC). However, the development of drug resistance limits its clinical applications. This study aims to address the challenge of everolimus resistance and provide new insights into the treatment of advanced RCC. Here, the cytotoxicity of the DNA methyltransferase 1 (DNMT1) inhibitor SGI-1027 in inducing cell vacuolation and methuosis is discovered and demonstrated for the first time. Additionally, SGI-1027 exerts synergistic effects with everolimus, as their combination suppresses the growth, migration, and invasion of renal cancer cells. Mechanistically, apoptosis and GSDME-dependent pyroptosis triggered by lysosomal membrane permeability (LMP) are observed. The upregulation of GSDME expression and increased lysosomal activity in renal cancer cells provide a therapeutic window for the combination of these two drugs to treat renal cancer. The combination treatment exhibits effective anti-tumor activity and is well tolerated in a subcutaneous tumor model. Overall, this study validates and reveals the specific cytotoxicity property of SGI-1027 and its potent synergistic effect with everolimus, offering new insights into advanced RCC therapy and everolimus-resistance overcoming.']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]2025-11-11 00:29:31 ML8136-T2YU.local httpx[7485] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-11 00:30:06 ML8136-T2YU.local httpx[7485] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating: 100%|██████████| 1/1 [00:44<00:00, 44.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGAS results: {'faithfulness': 0.9333}\n",
      "<openai.OpenAI object at 0x34def3890>\n"
     ]
    }
   ],
   "source": [
    "test = compute_ragas_faithfulness(abstract_summaries, abstracts, ragas_prompt)\n",
    "print(client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
