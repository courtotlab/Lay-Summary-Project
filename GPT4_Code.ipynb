{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc43f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import necessary libraries\n",
    "\n",
    "!python3 -m pip install pandas openpyxl metapub transformers torch torchvision tensorflow ragas langchain openai tiktoken python-dotenv tf-keras scikit-learn biopython beautifulsoup4 lxml\n",
    "import pandas as pd\n",
    "import json\n",
    "from metapub import PubMedFetcher\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import reduce\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from Bio import Entrez\n",
    "from bs4 import BeautifulSoup\n",
    "from ragas.metrics import faithfulness\n",
    "from ragas.evaluation import evaluate\n",
    "from langchain.schema import Document\n",
    "from datasets import Dataset\n",
    "!python3 -m pip install textstat\n",
    "import time\n",
    "import textstat\n",
    "from pathlib import Path\n",
    "!python3 -m pip install --upgrade openai nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "import asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c61905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv(\"\")\n",
    "openai_api_key = os.environ.get(\"API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"API key not found.\")\n",
    "else:\n",
    "    print(f\"API Key Loaded: {openai_api_key[:4]}...\")\n",
    "\n",
    "# OpenAI client\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Load configuration\n",
    "with open(\"\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "num_of_articles = config[\"num_of_articles\"]\n",
    "max_summary_length = config[\"max_summary_length\"]\n",
    "min_summary_length = config[\"min_summary_length\"]\n",
    "\n",
    "# Set Entrez email\n",
    "Entrez.email = \"\"  \n",
    "\n",
    "# Fetch full texts \n",
    "def fetch_full_texts(pmids, fetcher):\n",
    "    time.sleep(1) \n",
    "    full_texts, titles = {}, {}\n",
    "\n",
    "    print(f\"Retrieved PMIDs: {pmids}\")\n",
    "    print(f\"Number of PMIDs retrieved: {len(pmids)}\")\n",
    "\n",
    "    for pmid in pmids:\n",
    "        try:\n",
    "            article = fetcher.article_by_pmid(pmid)\n",
    "            titles[pmid] = article.title\n",
    "            \n",
    "            pmcid = article.pmc\n",
    "            if pmcid:\n",
    "                handle = Entrez.efetch(db=\"pmc\", id=pmcid, rettype=\"xml\", retmode=\"xml\")\n",
    "                xml_data = handle.read()\n",
    "                handle.close()\n",
    "\n",
    "                soup = BeautifulSoup(xml_data, features=\"xml\")\n",
    "\n",
    "                paragraphs = soup.find_all(\"p\")\n",
    "                sections = soup.find_all(\"sec\")\n",
    "\n",
    "                text_chunks = [p.get_text() for p in paragraphs]\n",
    "                if not text_chunks and sections:\n",
    "                    # Fallback to extracting from section text\n",
    "                    text_chunks = [s.get_text() for s in sections]\n",
    "\n",
    "                full_text = \"\\n\".join(p.get_text() for p in paragraphs)\n",
    "                full_texts[pmid] = full_text if full_text.strip() else \"Full text unavailable\"\n",
    "                \n",
    "            else:\n",
    "                full_texts[pmid] = \"Full text unavailable\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching full text for PMID {pmid}: {e}\")\n",
    "            titles[pmid] = titles.get(pmid, \"Unavailable\")\n",
    "            full_texts[pmid] = \"Full text unavailable\"\n",
    "    return titles, full_texts\n",
    "    \n",
    "\n",
    "def fetch_abstracts(pmids, fetcher):\n",
    "    abstracts = {}\n",
    "    titles = {}\n",
    "    \n",
    "    for pmid in pmids:\n",
    "        try:\n",
    "            article = fetcher.article_by_pmid(pmid)\n",
    "            titles[pmid] = article.title\n",
    "            abstracts[pmid] = article.abstract if article.abstract else \"Abstract unavailable\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching abstract for PMID {pmid}: {e}\")\n",
    "            titles[pmid] = titles.get(pmid, \"Unavailable\")\n",
    "            abstracts[pmid] = \"Abstract unavailable\"\n",
    "    return titles, abstracts\n",
    "\n",
    "async_client = AsyncOpenAI(api_key=openai_api_key)\n",
    "\n",
    "async def async_summarize(pmid, text, max_length):\n",
    "    if not text or text == \"Full text unavailable\":\n",
    "        return pmid, \"No text available\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"Summarize this article in 250 to 350 words for a 2nd grade lay audience using simple words. \"\n",
    "        f\"The tone should be casual. Avoid emotive or negative language such as battle or fight. \"\n",
    "        f\"Keep words under 4 syllables and sentences under 10 words: {text}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = await async_client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes medical research.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        return pmid, content\n",
    "    except Exception as e:\n",
    "        return pmid, f\"Error summarizing: {e}\"\n",
    "\n",
    "async def gpt4_summarize_async(texts, max_length, concurrency=15):\n",
    "    semaphore = asyncio.Semaphore(concurrency)\n",
    "\n",
    "    async def limited_summary(pmid, text):\n",
    "        async with semaphore:\n",
    "            return await async_summarize(pmid, text, max_length)\n",
    "\n",
    "    tasks = [limited_summary(pmid, text) for pmid, text in texts.items()]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return dict(results)\n",
    "\n",
    "\n",
    "def compute_readability(summary):\n",
    "    if summary and summary != \"No text available\":\n",
    "        flesch_score = textstat.flesch_reading_ease(summary)\n",
    "        grade_level = textstat.flesch_kincaid_grade(summary)\n",
    "        return flesch_score, grade_level\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def compute_ragas_faithfulness(summaries, references, prompt):\n",
    "    data = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": []\n",
    "    }\n",
    "    valid_pmids = []\n",
    "\n",
    "    for pmid, summary in summaries.items():\n",
    "        reference = references.get(pmid)\n",
    "        if (\n",
    "            summary \n",
    "            and reference \n",
    "            and summary != \"No text available\" \n",
    "            and reference != \"Full text unavailable\"\n",
    "        ):\n",
    "            data[\"question\"].append(prompt)\n",
    "            data[\"answer\"].append(summary)\n",
    "            data[\"contexts\"].append([reference])\n",
    "            valid_pmids.append(pmid)\n",
    "\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    results = evaluate(dataset, metrics=[faithfulness])\n",
    "    return dict(zip(valid_pmids, results[\"faithfulness\"]))\n",
    "\n",
    "\n",
    "# Fetch full_texts and abstracts\n",
    "if \"queries\" in config:\n",
    "        for query in config[\"queries\"]:\n",
    "            keyword = query[\"keyword\"]\n",
    "            output_file = query[\"output_file\"]\n",
    "\n",
    "            fetch = PubMedFetcher()\n",
    "            pmids = fetch.pmids_for_query(f\"{keyword} AND pmc_open_access[filter]\", retmax=num_of_articles)\n",
    "\n",
    "            titles, full_texts = fetch_full_texts(pmids, fetch)\n",
    "            \n",
    "            filtered_texts = {pmid: text for pmid, text in full_texts.items() if text != \"Full text unavailable\"}\n",
    "            full_text_summaries = await gpt4_summarize_async(filtered_texts, max_length=350)\n",
    "\n",
    "\n",
    "            titles, abstracts = fetch_abstracts(pmids, fetch)\n",
    "           \n",
    "\n",
    "            links = {pmid: f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\" for pmid in pmids}\n",
    "            abstract_summaries = await gpt4_summarize_async(abstracts, max_length=350)\n",
    "\n",
    "        \n",
    "            \n",
    "            # Define the evaluate_similarity function\n",
    "            def evaluate_similarity(abstract_summaries, full_text_summaries):\n",
    "                vectorizer = TfidfVectorizer()\n",
    "                tfidf_matrix = vectorizer.fit_transform([abstract_summaries, full_text_summaries])\n",
    "                similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "                return similarity[0][0]\n",
    "            \n",
    "            similarity_scores = {\n",
    "                pmid: evaluate_similarity(abstract_summaries[pmid], full_text_summaries[pmid])\n",
    "                for pmid in abstract_summaries\n",
    "                if abstract_summaries[pmid] != \"No text available\"\n",
    "                and full_text_summaries.get(pmid)\n",
    "                and full_text_summaries[pmid] != \"No text available\"\n",
    "            }\n",
    "\n",
    "            # Calculate readability scores for abstract summaries\n",
    "            abstract_readability = {\n",
    "                pmid: compute_readability(abstract_summaries[pmid])\n",
    "                for pmid in abstract_summaries\n",
    "            }\n",
    "            \n",
    "\n",
    "\n",
    "            # Calculate readability scores for full text summaries\n",
    "            full_text_readability = {\n",
    "                pmid: compute_readability(full_text_summaries[pmid])\n",
    "                for pmid in full_text_summaries\n",
    "            }\n",
    "\n",
    "\n",
    "            # Full text availability\n",
    "            full_text_availability = {\n",
    "                pmid: \"Available\" if full_texts[pmid] != \"Full text unavailable\" else \"Unavailable\"\n",
    "                for pmid in pmids\n",
    "            }\n",
    "\n",
    "            # Define the prompt you used for summarization\n",
    "            ragas_prompt = (\"Summarize this article in 250 to 350 words for a 2nd grade lay audience using simple words.\"\n",
    "                            \"The tone should be casual.\"\n",
    "                            \"Avoid emotive or negative language such as battle or fight.\"\n",
    "                            \"Keep words under 4 syllables and sentences under 10 words.\"\n",
    "                            )\n",
    "\n",
    "            # Compute RAGAS faithfulness\n",
    "            abstract_ragas_faithfulness = compute_ragas_faithfulness(abstract_summaries, abstracts, ragas_prompt)\n",
    "            fulltext_ragas_faithfulness = compute_ragas_faithfulness(full_text_summaries, full_texts, ragas_prompt)\n",
    "\n",
    "\n",
    "            # Prepare DataFrames\n",
    "            Title = pd.DataFrame(list(titles.items()), columns=[\"pmid\", \"Title\"])\n",
    "            Link = pd.DataFrame(list(links.items()), columns=[\"pmid\", \"Link\"])\n",
    "            Abstract = pd.DataFrame(list(abstracts.items()), columns=[\"pmid\", \"Abstract\"])\n",
    "            Abstract = Abstract.assign(\n",
    "                Abstract=lambda df: df[\"Abstract\"].str.replace(\"\\n\", \" \")\n",
    "            )\n",
    "            FullTextFlag = pd.DataFrame(list(full_text_availability.items()), columns=[\"pmid\", \"FullText_Availability\"])\n",
    "            Abstract_Summary = pd.DataFrame(list(abstract_summaries.items()), columns=[\"pmid\", \"Abstract_Summary\"])\n",
    "            Full_Text_Summary = pd.DataFrame(list(full_text_summaries.items()), columns=[\"pmid\", \"Full_Text_Summary\"])\n",
    "            Similarity = pd.DataFrame(list(similarity_scores.items()), columns=[\"pmid\", \"Abstract_vs_FullText_Similarity\"])\n",
    "            \n",
    "            Abstract_Readability = pd.DataFrame([\n",
    "                {\"pmid\": pmid, \n",
    "                \"Abstract_Flesch_Reading_Ease\": scores[0], \n",
    "                \"Abstract_Flesch_Kincaid_Grade\": scores[1]}\n",
    "                for pmid, scores in abstract_readability.items()\n",
    "            ])\n",
    "            \n",
    "\n",
    "            Full_Text_Readability = pd.DataFrame([\n",
    "                {\"pmid\": pmid, \n",
    "                \"FullText_Flesch_Reading_Ease\": scores[0], \n",
    "                \"FullText_Flesch_Kincaid_Grade\": scores[1]}\n",
    "                for pmid, scores in full_text_readability.items()\n",
    "            ])\n",
    "            \n",
    "            # RAGAS faithfulness scores\n",
    "            Abstract_RAGAS_Faithfulness = pd.DataFrame(list(abstract_ragas_faithfulness.items()), columns=[\"pmid\", \"Abstract_RAGAS_Faithfulness\"])\n",
    "            FullText_RAGAS_Faithfulness = pd.DataFrame(list(fulltext_ragas_faithfulness.items()), columns=[\"pmid\", \"FullText_RAGAS_Faithfulness\"])\n",
    "\n",
    "\n",
    "            # Combine all DataFrames\n",
    "            data_frames = [\n",
    "                Title, \n",
    "                Link, \n",
    "                Abstract, \n",
    "                FullTextFlag, \n",
    "                Abstract_Summary, \n",
    "                Full_Text_Summary, \n",
    "                Similarity,\n",
    "                Abstract_Readability,\n",
    "                Full_Text_Readability,\n",
    "                Abstract_RAGAS_Faithfulness,\n",
    "                FullText_RAGAS_Faithfulness\n",
    "            ]\n",
    "\n",
    "            # Combine all DataFrames\n",
    "            df_full = reduce(lambda left, right: pd.merge(left, right, on=\"pmid\", how=\"outer\"), data_frames)\n",
    "            \n",
    "            # Print Availability Counts\n",
    "            print(f\"Full Text Availability for keyword '{keyword}':\")\n",
    "            availability_counts = df_full[\"FullText_Availability\"].value_counts()\n",
    "            print(\"Full Text Availability Counts:\")\n",
    "            print(availability_counts)\n",
    "\n",
    "            # Filter to keep only articles with full text available\n",
    "            df_full = df_full[df_full[\"FullText_Availability\"] == \"Available\"]\n",
    "\n",
    "            # Save the DataFrame to a CSV file with a timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            base_name, _ = os.path.splitext(output_file)\n",
    "            output_file_with_timestamp = f\"{base_name}_{timestamp}.csv\"\n",
    "\n",
    "            # Specify the output directory\n",
    "            output_dir = Path(\"\")\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            full_output_path = output_dir / output_file_with_timestamp\n",
    "            df_full.to_csv(full_output_path, index=False)\n",
    "\n",
    "            print(f\"Data for keyword '{keyword}' saved to: {output_file_with_timestamp}\")\n",
    "else:\n",
    "    print(\"No queries found in the configuration file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
